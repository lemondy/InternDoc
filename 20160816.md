##今日完成总结
1. case when语句： 
  ``` 
SELECT name, salary, CASE 
  WHEN salaray < 5000.0 THEN 'low' 
  WHEN salary < 7000.0 THEN 'middle' 
  WHEN salary<10000.0 THEN 'high' 
  ELSE 'very high' END AS bracket 
  FROM employees; 
  ```

2. Hive 中大多数查询会触发一个 MapReduce 任务，然而在本地模式，不必使用MapReduce。当设置了属性 hive.exec.mode.local.auto=true; 时，Hive 会尝试使用本地模式执行其他的操作。可以将 `set hive.exec.mode.local.auto=true;` 这个设置增加到 `.hiverc` 配置文件中，就不用每次都设置一遍。
3. 判断是否相等用`=`，而不是用 `==`；正则表达式进行匹配的方式为： A RLIKE B, A REGEXP B， B 是一个正则表达式，如果A与其匹配，则返回 TRUE，反之返回 FALSE。 正则表达式匹配： `SELECT name, address FROM employees WHERE address.street LIKE '.*(Chicago|Ontario).*';`
4. **浮点数**比较的一个常见陷阱出现在不同类型间作比较的时候（Float 和 Double），通常会有隐士从窄类转换到宽泛类型。对于 DOUBLE 和 FLOAT 存储的位长不一样，精度不一样，进行比较时会有问题。一种做法是进行比较的时候将手动转换成一致 cast 函数然后再进行比较；另外一种比较耗时的方式是将他们存储为 String 类型，再转换成数值比较。**将浮点数转换成整数的推荐方式是使用round函数或者 floor函数，而不是使用类型转换操作符cast**
5. Having 语句过滤 group by 产生的分组结果。

6. 内连接：只有两个表中都存在的记录才会被保留下来。默认情况下，写 join on指的是内连接。多张表连接：

  ```
  SELECT a.ymd, a.price_close, b.price_close, c.price_close
  FROM stocks a JOIN stocks b ON a.ymd=b.ymd
              JOIN stocks c ON a.ymd=c.ymd
    WHERE a.symbol='apple' AND b.symbol='IBM' and c.symbol='GE';
  ```

7. Hive 假定在进行连接查询中最后一张表是最大的，在对每行记录进行连接的操作时，它会尝试将其他表缓存起来，然后扫描最后那个表进行计算。因此，用户需要保证连续查询中的表的大小是从左到右依次增加的。
8. **左半开连接（LEFT SEMI JOIN）**会返回左边表的记录，前提是其记录对于右边表满足 ON 语句中的判定条件。
9. **ORDER BY** 会对查询结果集执行一个全局的排序，也就是说所有的数据都通过一个 reducer 进行处理。对于大数据集，这个过程可能会消耗太过漫长的时间来执行。 Hive 中提供了 **SORT BY**，如果设置了 mapred.reduce.tasks>1, 其只会在每个 reducer 中对数据进行排序，也就是执行一个局部排序过程。节省后面全局排序时间。 **Distribute By** 保证了具有相同的字段的记录会被分发到同一个reducer中进行处理。

10. Hive 中可以对表进行分桶抽样来选择具有代表性的查询结果，而不是全部的数据。SELECT * FROM numbers TABLESAMPLE(BUCKET 3 OUT OF 10 ON rand()) s;
11. UDF（user define function）: 编写一个 UDF 函数需要继承 UDF 类并实现 evaluate() 函数。在查询过程中，查询对应的每个应用到这个函数的地方都会对这个类进行实例化。对于每行输入都会调用到 evaluate 函数，该函数处理后的值会返回给 Hive。evaluate函数可以被重载。 编写完 UDF 代码，导出为jar文件，然后利用 add jar /path/to/udf.jar 添加到hive中，接着利用 create temporary function udf as 'com.example.udf'; 创建了自定义函数名称，接着就可以在 Hive 中调用该 udf 函数。

### 优化
1. 使用sort by 而不是 order by， 因为sort by 会对每个 reducer 的进行排序，当 set mapred.reduce.tasks > 1， 每个 reduce 中的记录有序，若要整体有序，进行下归并排序即可，相对 order by 省时。
2. group by 优化： 1) Map 端聚合，并不是所有的聚合都是在 reducer 端完成，可以现在 map 端进行局部聚合，最后在 Reduce 端做全局聚合得到最终结果，set hive.map.aggr=true, hive.groupy.mapaggr.checkinterval=<numbers> 默认值为100000； 2）数据倾斜，有数据倾斜的时候要进行负载均衡。set hive.groupby.skewindata=true;启用均衡。
